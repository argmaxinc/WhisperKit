openapi: 3.0.0
info:
  title: WhisperKit Local Server API
  description: |-
    Local audio transcription and translation API for WhisperKit.

    ⚠️  WARNING: This file is auto-generated by generate_local_server_openapi.py script.
       Do not edit manually - changes will be overwritten.

    Generated from OpenAI OpenAPI spec v2.3.0.
    Source: https://github.com/openai/openai-openapi/blob/manual_spec/openapi.yaml

    To regenerate this file:
       make generate-server         # Complete workflow
  version: 1.0.0
paths:
  /audio/transcriptions:
    post:
      operationId: createTranscription
      summary: Transcribes audio into the input language.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateTranscriptionRequest"
            encoding:
              file:
                contentType: '*/*'
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                oneOf:
                - $ref: "#/components/schemas/CreateTranscriptionResponseJson"
                - $ref: "#/components/schemas/CreateTranscriptionResponseVerboseJson"
                discriminator:
                  propertyName: type
            text/event-stream:
              schema:
                $ref: "#/components/schemas/CreateTranscriptionResponseStreamEvent"
  /audio/translations:
    post:
      operationId: createTranslation
      summary: Translates audio into English.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateTranslationRequest"
            encoding:
              file:
                contentType: '*/*'
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                oneOf:
                - $ref: "#/components/schemas/CreateTranslationResponseJson"
                - $ref: "#/components/schemas/CreateTranslationResponseVerboseJson"
components:
  schemas:
    CreateTranscriptionRequest:
      type: object
      additionalProperties: false
      properties:
        file:
          description: >
            The audio file object (not file name) to transcribe, in one of these
            formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
          type: string
        model:
          description: >
            ID of the model to use. The options are `gpt-4o-transcribe`,
            `gpt-4o-mini-transcribe`, and `whisper-1` (which is powered by our
            open source Whisper V2 model).
          example: gpt-4o-transcribe
          anyOf:
          - type: string
          - type: string
            enum:
            - whisper-1
            - gpt-4o-transcribe
            - gpt-4o-mini-transcribe
            x-stainless-const: true
          x-oaiTypeLabel: string
        language:
          description: >
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)
            (e.g. `en`) format will improve accuracy and latency.
          type: string
        prompt:
          description: >
            An optional text to guide the model's style or continue a previous
            audio segment. The [prompt](/docs/guides/speech-to-text#prompting)
            should match the audio language.
          type: string
        response_format:
          $ref: "#/components/schemas/AudioResponseFormat"
        temperature:
          description: >
            The sampling temperature, between 0 and 1. Higher values like 0.8
            will make the output more random, while lower values like 0.2 will
            make it more focused and deterministic. If set to 0, the model will
            use [log probability](https://en.wikipedia.org/wiki/Log_probability)
            to automatically increase the temperature until certain thresholds
            are hit.
          type: number
          default: 0
        include[]:
          description: >
            Additional information to include in the transcription response. 

            `logprobs` will return the log probabilities of the tokens in the 

            response to understand the model's confidence in the transcription. 

            `logprobs` only works with response_format set to `json` and only
            with 

            the models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`.
          type: array
          items:
            $ref: "#/components/schemas/TranscriptionInclude"
        timestamp_granularities[]:
          description: >
            The timestamp granularities to populate for this transcription.
            `response_format` must be set `verbose_json` to use timestamp
            granularities. Either or both of these options are supported:
            `word`, or `segment`. Note: There is no additional latency for
            segment timestamps, but generating word timestamps incurs additional
            latency.
          type: array
          items:
            type: string
            enum:
            - word
            - segment
          default:
          - segment
        stream:
          description: |
            If set to true, the model response data will be streamed to the client
            as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). 
            See the [Streaming section of the Speech-to-Text guide](/docs/guides/speech-to-text?lang=curl#streaming-transcriptions)
            for more information.

            Note: Streaming is not supported for the `whisper-1` model and will be ignored.
          type: boolean
          nullable: true
          default: false
      required:
      - file
      - model
    CreateTranscriptionResponseJson:
      type: object
      description: Represents a transcription response returned by model, based on
        the provided input.
      properties:
        text:
          type: string
          description: The transcribed text.
        logprobs:
          type: array
          optional: true
          description: >
            The log probabilities of the tokens in the transcription. Only
            returned with the models `gpt-4o-transcribe` and
            `gpt-4o-mini-transcribe` if `logprobs` is added to the `include`
            array.
          items:
            type: object
            properties:
              token:
                type: string
                description: The token in the transcription.
              logprob:
                type: number
                description: The log probability of the token.
              bytes:
                type: array
                items:
                  type: number
                description: The bytes of the token.
        type:
          type: string
          description: The type of response
          enum:
          - CreateTranscriptionResponseJson
      required:
      - text
      - type
    CreateTranscriptionResponseStreamEvent:
      anyOf:
      - $ref: "#/components/schemas/TranscriptTextDeltaEvent"
      - $ref: "#/components/schemas/TranscriptTextDoneEvent"
      discriminator:
        propertyName: type
    CreateTranscriptionResponseVerboseJson:
      type: object
      description: Represents a verbose json transcription response returned by model,
        based on the provided input.
      properties:
        language:
          type: string
          description: The language of the input audio.
        duration:
          type: number
          description: The duration of the input audio.
        text:
          type: string
          description: The transcribed text.
        words:
          type: array
          description: Extracted words and their corresponding timestamps.
          items:
            $ref: "#/components/schemas/TranscriptionWord"
        segments:
          type: array
          description: Segments of the transcribed text and their corresponding details.
          items:
            $ref: "#/components/schemas/TranscriptionSegment"
        type:
          type: string
          description: The type of response
          enum:
          - CreateTranscriptionResponseVerboseJson
      required:
      - language
      - duration
      - text
      - type
    CreateTranslationRequest:
      type: object
      additionalProperties: false
      properties:
        file:
          description: >
            The audio file object (not file name) translate, in one of these
            formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
          type: string
        model:
          description: >
            ID of the model to use. Only `whisper-1` (which is powered by our
            open source Whisper V2 model) is currently available.
          example: whisper-1
          anyOf:
          - type: string
          - type: string
            enum:
            - whisper-1
            x-stainless-const: true
          x-oaiTypeLabel: string
        prompt:
          description: >
            An optional text to guide the model's style or continue a previous
            audio segment. The [prompt](/docs/guides/speech-to-text#prompting)
            should be in English.
          type: string
        response_format:
          description: >
            The format of the output, in one of these options: `json`, `text`,
            `srt`, `verbose_json`, or `vtt`.
          type: string
          enum:
          - json
          - text
          - srt
          - verbose_json
          - vtt
          default: json
        temperature:
          description: >
            The sampling temperature, between 0 and 1. Higher values like 0.8
            will make the output more random, while lower values like 0.2 will
            make it more focused and deterministic. If set to 0, the model will
            use [log probability](https://en.wikipedia.org/wiki/Log_probability)
            to automatically increase the temperature until certain thresholds
            are hit.
          type: number
          default: 0
        language:
          description: >-
            The language of the input audio. Supplying the input language in ISO-639-1
            format (e.g. 'es') will improve translation accuracy and latency.
          type: string
      required:
      - file
      - model
    CreateTranslationResponseJson:
      type: object
      properties:
        text:
          type: string
      required:
      - text
    CreateTranslationResponseVerboseJson:
      type: object
      properties:
        language:
          type: string
          description: The language of the output translation (always `english`).
        duration:
          type: number
          description: The duration of the input audio.
        text:
          type: string
          description: The translated text.
        segments:
          type: array
          description: Segments of the translated text and their corresponding details.
          items:
            $ref: "#/components/schemas/TranscriptionSegment"
      required:
      - language
      - duration
      - text
    AudioResponseFormat:
      description: >
        The format of the output, in one of these options: `json`, `text`,
        `srt`, `verbose_json`, or `vtt`. For `gpt-4o-transcribe` and
        `gpt-4o-mini-transcribe`, the only supported format is `json`.
      type: string
      enum:
      - json
      - text
      - srt
      - verbose_json
      - vtt
      default: json
    TranscriptTextDeltaEvent:
      type: object
      description: >-
        Emitted when there is an additional text delta. This is also the first event
        emitted when the transcription starts. Only emitted when you [create a transcription](/docs/api-reference/audio/create-transcription)
        with the `Stream` parameter set to `true`.
      properties:
        type:
          type: string
          description: |
            The type of the event. Always `transcript.text.delta`.
          enum:
          - transcript.text.delta
          x-stainless-const: true
        delta:
          type: string
          description: |
            The text delta that was additionally transcribed.
        logprobs:
          type: array
          description: >
            The log probabilities of the delta. Only included if you [create a
            transcription](/docs/api-reference/audio/create-transcription) with
            the `include[]` parameter set to `logprobs`.
          items:
            type: object
            properties:
              token:
                type: string
                description: |
                  The token that was used to generate the log probability.
              logprob:
                type: number
                description: |
                  The log probability of the token.
              bytes:
                type: array
                description: |
                  The bytes that were used to generate the log probability.
      required:
      - type
      - delta
    TranscriptTextDoneEvent:
      type: object
      description: >-
        Emitted when the transcription is complete. Contains the complete transcription
        text. Only emitted when you [create a transcription](/docs/api-reference/audio/create-transcription)
        with the `Stream` parameter set to `true`.
      properties:
        type:
          type: string
          description: |
            The type of the event. Always `transcript.text.done`.
          enum:
          - transcript.text.done
          x-stainless-const: true
        text:
          type: string
          description: |
            The text that was transcribed.
        logprobs:
          type: array
          description: >
            The log probabilities of the individual tokens in the transcription.
            Only included if you [create a
            transcription](/docs/api-reference/audio/create-transcription) with
            the `include[]` parameter set to `logprobs`.
          items:
            type: object
            properties:
              token:
                type: string
                description: |
                  The token that was used to generate the log probability.
              logprob:
                type: number
                description: |
                  The log probability of the token.
              bytes:
                type: array
                description: |
                  The bytes that were used to generate the log probability.
      required:
      - type
      - text
    TranscriptionInclude:
      type: string
      enum:
      - logprobs
      default: []
    TranscriptionSegment:
      type: object
      properties:
        id:
          type: integer
          description: Unique identifier of the segment.
        seek:
          type: integer
          description: Seek offset of the segment.
        start:
          type: number
          format: float
          description: Start time of the segment in seconds.
        end:
          type: number
          format: float
          description: End time of the segment in seconds.
        text:
          type: string
          description: Text content of the segment.
        tokens:
          type: array
          items:
            type: integer
          description: Array of token IDs for the text content.
        temperature:
          type: number
          format: float
          description: Temperature parameter used for generating the segment.
        avg_logprob:
          type: number
          format: float
          description: Average logprob of the segment. If the value is lower than
            -1, consider the logprobs failed.
        compression_ratio:
          type: number
          format: float
          description: Compression ratio of the segment. If the value is greater than
            2.4, consider the compression failed.
        no_speech_prob:
          type: number
          format: float
          description: >-
            Probability of no speech in the segment. If the value is higher than 1.0
            and the `avg_logprob` is below -1, consider this segment silent.
      required:
      - id
      - seek
      - start
      - end
      - text
      - tokens
      - temperature
      - avg_logprob
      - compression_ratio
      - no_speech_prob
    TranscriptionWord:
      type: object
      properties:
        word:
          type: string
          description: The text content of the word.
        start:
          type: number
          format: float
          description: Start time of the word in seconds.
        end:
          type: number
          format: float
          description: End time of the word in seconds.
      required:
      - word
      - start
      - end
