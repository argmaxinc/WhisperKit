"""
Generate local server OpenAPI spec from OpenAI OpenAPI spec
to create a minimal localserver_openapi.yaml for WhisperKit.
"""

from ruamel.yaml import YAML as RuamelYAML
from ruamel.yaml.scalarstring import FoldedScalarString, LiteralScalarString
import sys
import requests
import copy
from pathlib import Path

def create_minimal_spec(version, openapi_version):
    """Create the minimal OpenAPI spec structure with only essential fields."""
    description_text = f'''Local audio transcription and translation API for WhisperKit.

⚠️  WARNING: This file is auto-generated by generate_local_server_openapi.py script.
   Do not edit manually - changes will be overwritten.

Generated from OpenAI OpenAPI spec v{version}.
Source: https://github.com/openai/openai-openapi/blob/manual_spec/openapi.yaml

To regenerate this file:
   make generate-server         # Complete workflow'''
    
    return {
        'openapi': openapi_version,
        'info': {
            'title': 'WhisperKit Local Server API',
            'description': LiteralScalarString(description_text),
            'version': '1.0.0'
        },
        'paths': {},
        'components': {
            'schemas': {}
        }
    }

def fetch_latest_openapi_spec():
    """Fetch the latest OpenAI OpenAPI spec from GitHub."""
    url = "https://raw.githubusercontent.com/openai/openai-openapi/manual_spec/openapi.yaml"
    print(f"Fetching latest OpenAI OpenAPI spec from {url}...")
    
    try:
        response = requests.get(url)
        response.raise_for_status()
        
        ryaml = RuamelYAML()
        ryaml.preserve_quotes = True
        return ryaml.load(response.text)
    except requests.RequestException as e:
        print(f"Error fetching latest spec: {e}")
        return None

def find_schema_refs(obj):
    """Recursively find all schema references in an object."""
    refs = set()
    
    def process_item(item):
        if isinstance(item, dict):
            for key, value in item.items():
                if key == '$ref' and isinstance(value, str) and value.startswith('#/components/schemas/'):
                    refs.add(value.split('/')[-1])
                else:
                    process_item(value)
        elif isinstance(item, list):
            for subitem in item:
                process_item(subitem)
    
    process_item(obj)
    return refs

def clean_spec(minimal_spec):
    """Clean up the spec by removing unnecessary fields and fixing formatting."""
    # Remove x-oaiMeta fields
    def remove_meta_fields(obj):
        if isinstance(obj, dict):
            obj.pop('x-oaiMeta', None)
            for value in obj.values():
                remove_meta_fields(value)
        elif isinstance(obj, list):
            for item in obj:
                remove_meta_fields(item)
    
    # Fix file field definitions for multipart compatibility
    def fix_file_fields(obj):
        if isinstance(obj, dict):
            for key, value in obj.items():
                if key == "file" and isinstance(value, dict):
                    value.pop("format", None)
                    value.pop("x-oaiTypeLabel", None)
                else:
                    fix_file_fields(value)
        elif isinstance(obj, list):
            for item in obj:
                fix_file_fields(item)
    
    # Add language parameter to translation requests
    def add_language_param(obj):
        if isinstance(obj, dict):
            for key, value in obj.items():
                if key == "CreateTranslationRequest" and isinstance(value, dict):
                    value.setdefault("properties", {})["language"] = {
                        "description": "The language of the input audio. Supplying the input language in ISO-639-1 format (e.g. 'es') will improve translation accuracy and latency.",
                        "type": "string"
                    }
                else:
                    add_language_param(value)
        elif isinstance(obj, list):
            for item in obj:
                add_language_param(item)
    
    # Fix multipart content type definitions
    def fix_multipart_types(obj):
        if isinstance(obj, dict):
            for key, value in obj.items():
                if key == "content" and isinstance(value, dict):
                    multipart = value.get("multipart/form-data", {})
                    if isinstance(multipart, dict) and "schema" in multipart:
                        multipart.setdefault("encoding", {})["file"] = {"contentType": "*/*"}
                else:
                    fix_multipart_types(value)
        elif isinstance(obj, list):
            for item in obj:
                fix_multipart_types(item)
    
    # Add discriminator and type fields to transcription response schemas
    def add_discriminator(obj):
        if isinstance(obj, dict):
            for key, value in obj.items():
                if key == "paths" and isinstance(value, dict):
                    # Check for transcription endpoint
                    transcription_path = value.get("/audio/transcriptions", {})
                    if isinstance(transcription_path, dict):
                        post_method = transcription_path.get("post", {})
                        if isinstance(post_method, dict):
                            responses = post_method.get("responses", {})
                            json_response = responses.get("200", {}).get("content", {}).get("application/json", {})
                            if isinstance(json_response, dict) and "schema" in json_response:
                                schema = json_response["schema"]
                                if isinstance(schema, dict) and "oneOf" in schema:
                                    # Add discriminator if not already present
                                    if "discriminator" not in schema:
                                        schema["discriminator"] = {
                                            "propertyName": "type"
                                        }
                elif key == "components" and isinstance(value, dict):
                    schemas = value.get("schemas", {})
                    if isinstance(schemas, dict):
                        # Add type field to CreateTranscriptionResponseJson
                        if "CreateTranscriptionResponseJson" in schemas:
                            response_schema = schemas["CreateTranscriptionResponseJson"]
                            if isinstance(response_schema, dict) and "properties" in response_schema:
                                properties = response_schema["properties"]
                                if "type" not in properties:
                                    properties["type"] = {
                                        "type": "string",
                                        "description": "The type of response",
                                        "enum": ["CreateTranscriptionResponseJson"]
                                    }
                                if "required" in response_schema:
                                    if "type" not in response_schema["required"]:
                                        response_schema["required"].append("type")
                                else:
                                    response_schema["required"] = ["type"]
                        
                        # Add type field to CreateTranscriptionResponseVerboseJson
                        if "CreateTranscriptionResponseVerboseJson" in schemas:
                            response_schema = schemas["CreateTranscriptionResponseVerboseJson"]
                            if isinstance(response_schema, dict) and "properties" in response_schema:
                                properties = response_schema["properties"]
                                if "type" not in properties:
                                    properties["type"] = {
                                        "type": "string",
                                        "description": "The type of response",
                                        "enum": ["CreateTranscriptionResponseVerboseJson"]
                                    }
                                if "required" in response_schema:
                                    if "type" not in response_schema["required"]:
                                        response_schema["required"].append("type")
                                else:
                                    response_schema["required"] = ["type"]
                        
                        # Continue processing nested objects
                        add_discriminator(schemas)
                else:
                    add_discriminator(value)
        elif isinstance(obj, list):
            for item in obj:
                add_discriminator(item)
    
    # Apply folded scalars to long descriptions for cleaner YAML
    def apply_folded_scalars(obj):
        if isinstance(obj, dict):
            for key, value in obj.items():
                if key == 'description' and isinstance(value, str):
                    if '\n' not in value and len(value) > 120:
                        obj[key] = FoldedScalarString(value)
                else:
                    apply_folded_scalars(value)
        elif isinstance(obj, list):
            for item in obj:
                apply_folded_scalars(item)
    
    print("Cleaning up spec...")
    remove_meta_fields(minimal_spec)
    fix_file_fields(minimal_spec)
    add_language_param(minimal_spec)
    fix_multipart_types(minimal_spec)
    add_discriminator(minimal_spec)
    apply_folded_scalars(minimal_spec)

def extract_audio_endpoints(input_file, output_file, use_latest=False):
    """Extract only audio transcription and translation endpoints and their schemas."""
    
    if use_latest:
        full_spec = fetch_latest_openapi_spec()
        if full_spec is None:
            print("Failed to fetch latest spec, falling back to local file...")
            use_latest = False
    
    if not use_latest:
        print(f"Reading {input_file}...")
        ryaml = RuamelYAML()
        ryaml.preserve_quotes = True
        with open(input_file, 'r') as f:
            full_spec = ryaml.load(f)
    
    version = full_spec.get('info', {}).get('version', 'unknown')
    openapi_version = full_spec.get('openapi', '3.0.0')
    print(f"Extracted version: {version}")
    print(f"OpenAPI version: {openapi_version}")
    
    # Create minimal spec and extract audio endpoints
    minimal_spec = create_minimal_spec(version, openapi_version)
    
    audio_paths = ['/audio/transcriptions', '/audio/translations']
    for path in audio_paths:
        if path in full_spec['paths']:
            path_data = copy.deepcopy(full_spec['paths'][path])
            # Remove tags for cleaner output
            for method in path_data.values():
                if isinstance(method, dict):
                    method.pop('tags', None)
            minimal_spec['paths'][path] = path_data
            print(f"Added {path}")
        else:
            print(f"Warning: {path} not found in original spec")
    
    # Collect and add all required schemas
    used_schemas = find_schema_refs(minimal_spec['paths'])
    print(f"Found {len(used_schemas)} referenced schemas: {sorted(used_schemas)}")
    
    # Add schemas in order of appearance in original spec
    schema_order = list(full_spec['components']['schemas'].keys())
    added_schemas = set()
    
    # First pass: add directly referenced schemas
    for schema_name in schema_order:
        if schema_name in used_schemas:
            minimal_spec['components']['schemas'][schema_name] = full_spec['components']['schemas'][schema_name]
            added_schemas.add(schema_name)
            print(f"Added schema: {schema_name}")
    
    # Second pass: add any new schemas discovered in the added schemas
    while True:
        new_refs = set()
        for schema_name in list(minimal_spec['components']['schemas'].keys()):
            if schema_name not in added_schemas:
                continue
            schema_refs = find_schema_refs(minimal_spec['components']['schemas'][schema_name])
            new_refs.update(schema_refs - set(minimal_spec['components']['schemas'].keys()))
        
        if not new_refs:
            break
            
        print(f"Adding missing schemas: {', '.join(sorted(new_refs))}")
        for schema_name in schema_order:
            if schema_name in new_refs:
                minimal_spec['components']['schemas'][schema_name] = full_spec['components']['schemas'][schema_name]
                added_schemas.add(schema_name)
                print(f"Added schema: {schema_name}")
    
    print(f"Total schemas: {len(minimal_spec['components']['schemas'])}")
    
    # Clean up the spec
    clean_spec(minimal_spec)
    
    # Write the spec
    print(f"Writing {output_file}...")
    ryaml = RuamelYAML()
    ryaml.default_flow_style = False
    ryaml.width = 80
    ryaml.indent(mapping=2, sequence=2, offset=0)
    
    with open(output_file, 'w') as f:
        ryaml.dump(minimal_spec, f)
    
    print(f"Successfully created {output_file}")
    print(f"Original spec: {len(full_spec['paths'])} paths, {len(full_spec['components']['schemas'])} schemas")
    print(f"Minimal spec: {len(minimal_spec['paths'])} paths, {len(minimal_spec['components']['schemas'])} schemas")
    print(f"Generated from OpenAI OpenAPI spec v{version}")

if __name__ == '__main__':
    input_file = 'specs/openapi.yaml'
    output_file = 'specs/localserver_openapi.yaml'
    use_latest = '--latest' in sys.argv
    
    if use_latest:
        print("Using latest OpenAI OpenAPI spec from GitHub...")
    elif not Path(input_file).exists():
        print(f"Error: {input_file} not found")
        print("Use --latest to fetch from GitHub instead")
        sys.exit(1)
    
    extract_audio_endpoints(input_file, output_file, use_latest)
